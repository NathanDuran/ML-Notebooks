{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "   Id  SepalLength  SepalWidth  PetalLength  PetalWidth      Species\n",
      "0   1          5.1         3.5          1.4         0.2  Iris-setosa\n",
      "1   2          4.9         3.0          1.4         0.2  Iris-setosa\n",
      "2   3          4.7         3.2          1.3         0.2  Iris-setosa\n",
      "3   4          4.6         3.1          1.5         0.2  Iris-setosa\n",
      "4   5          5.0         3.6          1.4         0.2  Iris-setosa\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-68c3d93eb698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;31m# x_range = [i*10 for i in range(len(train_errors))]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;31m# figure, ax = plt.subplots(1, 2, figsize=(16, 6))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-68c3d93eb698>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, y, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;31m# Every 10 epochs record error and accuracy on training and test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-68c3d93eb698>\u001b[0m in \u001b[0;36mbackward_pass\u001b[1;34m(self, x, y, output, hidden_output, learning_rate)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# Calculate output layer error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0moutput_layer_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# Calculate output layer gradient from error and derivative of output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,3) (100,6) "
     ],
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,3) (100,6) ",
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns ;sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Read data from csv\n",
    "iris = pd.read_csv(\"data/Iris.csv\")\n",
    "print(iris.head())\n",
    "\n",
    "# Plot the various combinations of 2D graph\n",
    "#g = sns.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\")\n",
    "\n",
    "# Replace the species with 0, 1 or 2 as appropriate\n",
    "iris['Species'].replace(['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'], [0, 1, 2], inplace=True)\n",
    "\n",
    "# Get labels, flatten and encode to one-hot\n",
    "columns = ['Species']\n",
    "labels = pd.DataFrame(iris, columns=columns).to_numpy()\n",
    "labels = labels.flatten()\n",
    "labels = np.eye(np.max(labels) + 1)[labels]\n",
    "\n",
    "# Get Features\n",
    "columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "features = pd.DataFrame(iris, columns=columns).to_numpy()\n",
    "\n",
    "# Split data to training and test data, 2/3 for training and 1/3 for testing\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size=0.33)\n",
    "\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 200\n",
    "\n",
    "# Network architecture parameters\n",
    "num_features = len(train_x[0])\n",
    "num_classes = len(train_y[0])\n",
    "num_hidden_nodes = 6\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, num_inputs, num_outputs, num_hidden_nodes):\n",
    "        # Get the number of inputs, outputs and hidden nodes\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_ouputs = num_outputs\n",
    "        self.num_hidden_nodes = num_hidden_nodes\n",
    "        \n",
    "        # Initialise weights in the range -0.5 to 0.5\n",
    "        # Hidden layer weights with shape (number of input features x number of hidden nodes)\n",
    "        self.hidden_weights = np.random.uniform(-0.5, 0.5, size=(self.num_inputs, self.num_hidden_nodes))\n",
    "        self.hidden_bias = np.random.uniform(-0.5, 0.5, size=(1, self.num_hidden_nodes))\n",
    "        # Output layer weights with shape (number of hidden nodes x number of output classes)\n",
    "        self.output_weights = np.random.uniform(-0.5, 0.5, size=(self.num_hidden_nodes, self.num_ouputs))\n",
    "        self.output_bias = np.random.uniform(-0.5, 0.5, size=(1, self.num_ouputs))\n",
    "\n",
    "    # Sigmoid activation function and its derivative\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_deriv(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        \"\"\" Forward Pass - propagates input data through the network. \"\"\"\n",
    "        \n",
    "        # Input layer is just the input data\n",
    "        input_layer = x\n",
    "        # Hidden layer sigmoid(W * X + b)\n",
    "        hidden_output = self.sigmoid(np.dot(input_layer, self.hidden_weights) + self.hidden_bias)\n",
    "        # Output layer sigmoid(W * X + b)\n",
    "        output = self.sigmoid(np.dot(hidden_output, self.output_weights) + self.output_bias)\n",
    "        \n",
    "        # Return both layers output\n",
    "        return hidden_output, output\n",
    "    \n",
    "    def backward_pass(self, x, y, output, hidden_output, learning_rate):\n",
    "        \"\"\" Backpropagation - propagates the error backwards through the network. \"\"\"\n",
    "        \n",
    "        # Calculate output layer error\n",
    "        output_layer_error = y - output\n",
    "    \n",
    "        # Calculate output layer gradient from error and derivative of output\n",
    "        # Note: just need this layers error for the bias\n",
    "        output_layer_delta = output_layer_error * self.sigmoid_deriv(output)\n",
    "        output_bias_delta = np.sum(output_layer_error, axis=0)\n",
    "        \n",
    "        # Calculate hidden layer error (from the output layers weights and gradient)\n",
    "        hidden_layer_error = output_layer_delta.dot(self.output_weights.T)\n",
    "        \n",
    "        # Calculate hidden layer gradient\n",
    "        # Note: just need this layers error for the bias\n",
    "        hidden_layer_delta = hidden_layer_error * self.sigmoid_deriv(hidden_output)\n",
    "        hidden_bias_delta = np.sum(hidden_layer_error, axis=0)\n",
    "         \n",
    "        \"\"\" Update the Weights - update the weights using the error gradients and learning rate. \"\"\"\n",
    "        # Change in weight = learning rate * layers input * layers gradient\n",
    "        self.output_weights += learning_rate * hidden_output.T.dot(output_layer_delta)\n",
    "        self.output_bias += learning_rate * output_bias_delta\n",
    "        \n",
    "        self.hidden_weights += learning_rate * x.T.dot(hidden_layer_delta)\n",
    "        self.hidden_bias += learning_rate * hidden_bias_delta\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\" Generate predictions on input data. \"\"\"\n",
    "        \n",
    "        # Pass the data through the network and generate outputs\n",
    "        outputs, _ = self.forward_pass(x)\n",
    "        \n",
    "        # Prediction is the output node with the highest value\n",
    "        predictions = np.argmax(outputs)\n",
    "        return predictions\n",
    "    \n",
    "    def train(self, x, y, num_epochs, learning_rate):\n",
    "        \"\"\" Train the network on the input data. \"\"\"\n",
    "        \n",
    "        # For recording error and accuracy - for graph later\n",
    "        train_errors, test_errors = [], []\n",
    "        train_accuracies, test_accuracies = [], []\n",
    "        \n",
    "        # Train for number of epochs\n",
    "        for epoch in range(num_epochs+1):\n",
    "            outputs,hidden_output = self.forward_pass(x)\n",
    "            self.backward_pass(x, y, outputs, hidden_output, learning_rate)\n",
    "            \n",
    "            # Every 10 epochs record error and accuracy on training and test set\n",
    "            if (epoch % 10) == 0:\n",
    "                \n",
    "                # Mean squared error over all errors this epoch\n",
    "                error = np.square(y - outputs).mean() \n",
    "                train_errors.append(error)\n",
    "   \n",
    "                # Get the prediction i.e. the output with the highest value\n",
    "                predictions = self.predict(x)\n",
    "                # Get the actual labels\n",
    "                actual_labels = np.argmax(train_y)\n",
    "                \n",
    "                # If they match the prediction was correct\n",
    "                correct_predictions = np.sum(predictions == actual_labels)\n",
    "                accuracy = (100 / len(train_x)) * correct_predictions\n",
    "                train_accuracies.append(accuracy)\n",
    "               \n",
    "                # Test data forward pass\n",
    "                test_outputs, _ = self.forward_pass(test_y)\n",
    "                # Mean squared error over all errors\n",
    "                test_error = np.square(test_y - test_outputs).mean()\n",
    "                test_errors.append(test_error)\n",
    "        \n",
    "                # Get the prediction i.e. the output with the highest value\n",
    "                predictions = self.predict(test_x)\n",
    "                # Get the actual labels\n",
    "                actual_labels = np.argmax(test_y)\n",
    "                \n",
    "                # If they match the prediction was correct\n",
    "                correct_predictions = np.sum(predictions == actual_labels)\n",
    "                test_accuracy = (100 / len(test_x)) * correct_predictions\n",
    "                test_accuracies.append(test_accuracy)\n",
    "        \n",
    "                print(\"Epoch: \" + str(epoch) +\n",
    "                      \" Error: \" + str(round(error, 5)) +\n",
    "                      \" Accuracy: \" + str(accuracy) + \"%\" +\n",
    "                      \" Test Error: \" + str(round(test_error, 5)) +\n",
    "                      \" Accuracy: \" + str(test_accuracy) + \"%\")\n",
    "\n",
    "nn = NeuralNetwork(num_features, num_classes, num_hidden_nodes)\n",
    "nn.train(train_x, train_y, 200, 0.01)\n",
    "# x_range = [i*10 for i in range(len(train_errors))]\n",
    "# figure, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "# sns.lineplot(x=x_range, y=train_accuracies, color='b', ax=ax[0])\n",
    "# sns.lineplot(x=x_range, y=test_accuracies, color='r', ax=ax[0])\n",
    "# ax[0].title.set_text(\"Accuracy\")\n",
    "# sns.lineplot(x=x_range, y=train_errors, color='b', ax=ax[1])\n",
    "# sns.lineplot(x=x_range, y=test_errors, color='r', ax=ax[1])\n",
    "# ax[1].title.set_text(\"Error\")\n",
    "# ax[1].legend(['train', 'test'])\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}