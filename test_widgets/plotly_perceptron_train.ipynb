{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  AND  OR  XOR\n",
      "0   0   0    0   0    0\n",
      "1   0   1    0   1    1\n",
      "2   1   0    0   1    1\n",
      "3   1   1    1   1    0\n",
      "start model:\n",
      "{'weight_1': -0.23310693446878084, 'weight_2': 0.2241240728203332, 'bias_weight': -0.24046657130257842}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f76eae3b154469c8561f6f6dc026f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Button(button_style='success', description='Step', icon='step-forâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from binary_perceptron import BinaryPerceptronGraph\n",
    "#plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "data = pd.DataFrame({'x1': [0, 0, 1, 1], 'x2':[0, 1, 0, 1], \n",
    "                    'AND':[0, 0, 0, 1],  'OR':[0, 1, 1, 1], 'XOR':[0, 1, 1, 0]})\n",
    "print(data)\n",
    "\n",
    "learning_rate = 0.1\n",
    "# Set the weights to small random values in the range -0.5 to 0.5\n",
    "weight_1 = np.random.uniform(-0.5, 0.5)\n",
    "weight_2 = np.random.uniform(-0.5, 0.5)\n",
    "bias_weight = np.random.uniform(-0.5, 0.5)\n",
    "bias = 1\n",
    "model = {'weight_1':weight_1, 'weight_2':weight_2, 'bias_weight': bias_weight}\n",
    "print(\"start model:\")\n",
    "print(model)\n",
    "current_step = 0\n",
    "def train(target_outputs, step, num_steps):\n",
    "    # Unpack the model values into local variables\n",
    "    w1, w2, bw = model['weight_1'],  model['weight_2'], model['bias_weight']\n",
    "\n",
    "    # Loop over all of the input examples\n",
    "    for i in range(step, num_steps):\n",
    "        \n",
    "        # Calculate sum of weights\n",
    "        weight_sum = (data['x1'][i] * w1) + (data['x2'][i] * w2) + (bias * bw)\n",
    "        \n",
    "        # Activation (step) function\n",
    "        if weight_sum > 0:\n",
    "            activation = 1\n",
    "        else:\n",
    "            activation = 0\n",
    "\n",
    "        # Calculate error (target output - actual output)\n",
    "        error = target_outputs[i] - activation\n",
    "        \n",
    "        # Update weights (error * input * learning rate)\n",
    "        w1 += error * data['x1'][i] * learning_rate\n",
    "        w2 += error * data['x2'][i] * learning_rate\n",
    "        bw += error * bias * learning_rate\n",
    "        \n",
    "        # Update the graph\n",
    "        perceptron_graph.update_step(model, w1, w2, bw, error)\n",
    "        # Repack the model values from local variables\n",
    "        model['weight_1'], model['weight_2'], model['bias_weight'] = w1, w2, bw\n",
    "\n",
    "perceptron_graph = BinaryPerceptronGraph(data)\n",
    "train_widget = perceptron_graph.create_train_graph(train, learning_rate)\n",
    "display(train_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
